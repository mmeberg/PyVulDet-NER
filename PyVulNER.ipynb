{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1486084c-d93c-45f0-8c54-d6e99efcbf38",
      "metadata": {
        "id": "1486084c-d93c-45f0-8c54-d6e99efcbf38"
      },
      "outputs": [],
      "source": [
        "!pip install datasets transformers evaluate seqeval pynvml pyyaml h5py huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import requests\n",
        "import time\n",
        "import sys\n",
        "import json\n",
        "from requests_oauthlib import OAuth1Session\n",
        "from requests_oauthlib import OAuth1\n",
        "import base64\n",
        "from collections import Counter, defaultdict\n",
        "import transformers\n",
        "import random\n",
        "import datasets\n",
        "import tokenize\n",
        "import io\n",
        "import re\n",
        "import time\n",
        "import math\n",
        "import datetime"
      ],
      "metadata": {
        "id": "3mPEiWdJK0UJ"
      },
      "id": "3mPEiWdJK0UJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "59160c22-99cb-4800-b320-39421a5ed7d4",
      "metadata": {
        "tags": [],
        "id": "59160c22-99cb-4800-b320-39421a5ed7d4"
      },
      "source": [
        "# Data Collect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d6345c9-4a02-4e8a-ac22-b17767d1938f",
      "metadata": {
        "id": "8d6345c9-4a02-4e8a-ac22-b17767d1938f"
      },
      "outputs": [],
      "source": [
        "# GitHub Access Token\n",
        "with open('github_token', 'r') as accestoken:\n",
        "    access = accestoken.readline().replace(\"\\n\",\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1573991-8a7b-4470-978e-fb8390c22a66",
      "metadata": {
        "id": "f1573991-8a7b-4470-978e-fb8390c22a66"
      },
      "outputs": [],
      "source": [
        "%run -i commits_from_GitHub.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74408f4b-311e-4b5a-8024-29043b109ce8",
      "metadata": {
        "id": "74408f4b-311e-4b5a-8024-29043b109ce8"
      },
      "outputs": [],
      "source": [
        "%run -i commit_diffs.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db6aab37-7682-462e-bc5d-4afbad18b578",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "db6aab37-7682-462e-bc5d-4afbad18b578"
      },
      "outputs": [],
      "source": [
        "%run -i diff_commit_data.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dad427f-b2a1-4215-bb6c-2337b4ae7b52",
      "metadata": {
        "tags": [],
        "id": "6dad427f-b2a1-4215-bb6c-2337b4ae7b52"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run -i clean_and_shorten_data.py"
      ],
      "metadata": {
        "id": "iZLPA6TdQdiP"
      },
      "id": "iZLPA6TdQdiP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#roberta and codebert tokenization and embedding - input which one after file name\n",
        "%run -i create_dataset_roberta.py clean_dataset_short.pickle codebert"
      ],
      "metadata": {
        "id": "TdWnXhaTQpoh"
      },
      "id": "TdWnXhaTQpoh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#distilbert\n",
        "%run -i create_dataset_distilbert.py clean_dataset_short.pickle distilbert"
      ],
      "metadata": {
        "id": "MbBPjLf5QpgC"
      },
      "id": "MbBPjLf5QpgC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Development"
      ],
      "metadata": {
        "id": "VRLJrgC0uhTY"
      },
      "id": "VRLJrgC0uhTY"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers evaluate seqeval pynvml pyyaml h5py huggingface_hub"
      ],
      "metadata": {
        "id": "hph57h1Rujm5"
      },
      "id": "hph57h1Rujm5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import datasets\n",
        "import pickle\n",
        "from datasets import load_metric\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from pynvml import *\n",
        "import tensorflow as tf\n",
        "\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "#tqdmn = tqdm.notebook.tqdm\n",
        "\n",
        "import transformers\n",
        "from transformers import BertTokenizerFast\n",
        "from transformers import TFBertModel\n",
        "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
        "\n",
        "import sklearn\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from transformers import (\n",
        "   AutoConfig,\n",
        "   AutoTokenizer,\n",
        "   TFAutoModelForTokenClassification,\n",
        "   AdamW,\n",
        "   AdamWeightDecay)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "KpF4WR-mul8O"
      },
      "id": "KpF4WR-mul8O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#file = 'roberta_tagsandtokens_PADDED.pickle'\n",
        "file = 'distilbert_tagsandtokens_PADDED.pickle'\n",
        "#file = 'codebert_tagsandtokens_PADDED.pickle'\n",
        "with open(file, 'rb') as data:\n",
        "    dataset = pickle.load(data)\n",
        "dataset"
      ],
      "metadata": {
        "id": "iZW6KCD0uuWr"
      },
      "id": "iZW6KCD0uuWr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_choice = \"roberta-base\"\n",
        "tok_choice = \"roberta-base\"\n",
        "#model_choice = 'microsoft/codebert-base'\n",
        "#tok_choice = 'microsoft/codebert-base'\n",
        "#model_choice = \"distilbert-base-uncased\"\n",
        "#tok_choice = \"distilbert-base-uncased\""
      ],
      "metadata": {
        "id": "7O48h1TtuuUF"
      },
      "id": "7O48h1TtuuUF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = ['O',      #0\n",
        "              'B-rce',  #1\n",
        "              'I-rce',  #2\n",
        "              'B-oob',  #3\n",
        "              'I-oob',  #4\n",
        "              'B-xss',  #5\n",
        "              'I-xss',  #6\n",
        "              'B-sql',  #7\n",
        "              'I-sql',  #8\n",
        "              'B-iiv',  #9\n",
        "              'I-iiv',  #10\n",
        "              'B-pat',  #11\n",
        "              'I-pat',  #12\n",
        "             ]\n",
        "id2label = {i: label for i, label in enumerate(label_list)}\n",
        "label2id = {label: i for i, label in enumerate(label_list)}"
      ],
      "metadata": {
        "id": "x8WjSnoouuRZ"
      },
      "id": "x8WjSnoouuRZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
      ],
      "metadata": {
        "id": "Rm6sW70iuuOs"
      },
      "id": "Rm6sW70iuuOs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {i: label for i, label in enumerate(label_list)}\n",
        "label2id = {label: i for i, label in enumerate(label_list)}"
      ],
      "metadata": {
        "id": "lviM_FqPuuMG"
      },
      "id": "lviM_FqPuuMG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(model_choice, num_labels = len(label_list))\n",
        "\n",
        "model.config.id2label = id2label\n",
        "model.config.label2id = label2id"
      ],
      "metadata": {
        "id": "jgRXoxCVuuJo"
      },
      "id": "jgRXoxCVuuJo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)"
      ],
      "metadata": {
        "id": "rQWBbnCxwf0J"
      },
      "id": "rQWBbnCxwf0J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.AdamW(params=model.parameters(), lr=2e-5)"
      ],
      "metadata": {
        "id": "gMcGLFr3uuHN"
      },
      "id": "gMcGLFr3uuHN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "wG_hOpmRuuEX"
      },
      "id": "wG_hOpmRuuEX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "id": "9jJBwEPauuAv"
      },
      "id": "9jJBwEPauuAv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_data = DataLoader(\n",
        "    dataset[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
        ")\n",
        "eval_data = DataLoader(\n",
        "    dataset[\"validation\"], batch_size=8, collate_fn=data_collator\n",
        ")"
      ],
      "metadata": {
        "id": "wm_YB_luut7f"
      },
      "id": "wm_YB_luut7f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_scheduler\n",
        "\n",
        "num_epochs = 10\n",
        "num_training_steps = num_epochs * len(train_data)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "print(num_training_steps)"
      ],
      "metadata": {
        "id": "JP8LzEl8ut5D"
      },
      "id": "JP8LzEl8ut5D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = []\n",
        "model.train()\n",
        "for epoch in tqdmn(range(num_epochs)):\n",
        "    current_loss = 0\n",
        "    for i, batch in enumerate(tqdmn(train_data)):\n",
        "        # move the batch tensors to the same device as the\n",
        "        batch = { k: v.to(device) for k, v in batch.items() }\n",
        "        # send 'input_ids', 'attention_mask' and 'labels' to the model\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss #outputs[0]\n",
        "        loss.backward()\n",
        "        current_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        train_loss.append(current_loss / 10)\n",
        "        current_loss = 0\n",
        "\n",
        "    optimizer.step()\n",
        "    lr_scheduler.step()\n",
        "    optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "Il0MOD55wxTt"
      },
      "id": "Il0MOD55wxTt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "from huggingface_hub import login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "veR1hbxQwxRI"
      },
      "id": "veR1hbxQwxRI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('PyNERModel_dev')"
      ],
      "metadata": {
        "id": "SIJgsy9dwxOG"
      },
      "id": "SIJgsy9dwxOG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import whoami\n",
        "whoami()"
      ],
      "metadata": {
        "id": "bF_HggoSxCxc"
      },
      "id": "bF_HggoSxCxc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(repo_id = '') #need to input user id"
      ],
      "metadata": {
        "id": "dZ1WCoIAwxLJ"
      },
      "id": "dZ1WCoIAwxLJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Test"
      ],
      "metadata": {
        "id": "tWTgtIL5yXPq"
      },
      "id": "tWTgtIL5yXPq"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub datasets transformers torchview"
      ],
      "metadata": {
        "id": "u5iJZsQeyYN1"
      },
      "id": "u5iJZsQeyYN1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "from huggingface_hub import login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "0Ldcc70UybuX"
      },
      "id": "0Ldcc70UybuX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "#tok_choice = 'roberta-base'\n",
        "tok_choice = 'microsoft/codebert-base'\n",
        "#tok_choice = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(tok_choice)"
      ],
      "metadata": {
        "id": "XlyFKFssybr_"
      },
      "id": "XlyFKFssybr_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)"
      ],
      "metadata": {
        "id": "ARW4sWh4ybpq"
      },
      "id": "ARW4sWh4ybpq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "model = AutoModelForTokenClassification.from_pretrained('mmeberg/CoCo_PyVulDet_NER')\n",
        "#'mmeberg/CoCo_PyVulDet_NER'\n",
        "#'mmeberg/RoCo_PyVulDet_NER'\n",
        "#'mmeberg/RoRo_PyVulDet_NER'\n",
        "#'mmeberg/CoRo_PyVulDet_NER'\n",
        "#'mmeberg/DiDi_PyVulDet_NER'"
      ],
      "metadata": {
        "id": "CNOBRkr2ybmv"
      },
      "id": "CNOBRkr2ybmv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "tqdmn = tqdm.notebook.tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "x_w87Dcuybhq"
      },
      "id": "x_w87Dcuybhq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "qdhVxBrwybe7"
      },
      "id": "qdhVxBrwybe7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "id": "BEp1eb6YybcG"
      },
      "id": "BEp1eb6YybcG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.config"
      ],
      "metadata": {
        "id": "hmc-_B_XybU9"
      },
      "id": "hmc-_B_XybU9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GitHub Test Set"
      ],
      "metadata": {
        "id": "MvKAnoQByqmY"
      },
      "id": "MvKAnoQByqmY"
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import datasets\n",
        "\n",
        "file = 'PADDED_distilbert.pickle'\n",
        "with open(file, 'rb') as data:\n",
        "    dataset = pickle.load(data)\n",
        "dataset"
      ],
      "metadata": {
        "id": "KGOjmyKMyojz"
      },
      "id": "KGOjmyKMyojz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test_df = pd.DataFrame(dataset['test'])\n",
        "test_df = test_df[['input_ids', 'attention_mask', 'labels']]\n",
        "test_df.head(2)"
      ],
      "metadata": {
        "id": "POGiKsR4yogx"
      },
      "id": "POGiKsR4yogx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = datasets.Dataset.from_pandas(test_df)\n",
        "test_data.set_format(type='torch')"
      ],
      "metadata": {
        "id": "xazVXtb9yod7"
      },
      "id": "xazVXtb9yod7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.format['type']"
      ],
      "metadata": {
        "id": "NERD1gbuyoZM"
      },
      "id": "NERD1gbuyoZM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "test_data = DataLoader(\n",
        "    test_data, shuffle=True, batch_size=8, collate_fn=data_collator\n",
        ")"
      ],
      "metadata": {
        "id": "12LxEbGvyoRl"
      },
      "id": "12LxEbGvyoRl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = ['O',      #0\n",
        "              'B-rce',  #1\n",
        "              'I-rce',  #2\n",
        "              'B-oob',  #3\n",
        "              'I-oob',  #4\n",
        "              'B-xss',  #5\n",
        "              'I-xss',  #6\n",
        "              'B-sql',  #7\n",
        "              'I-sql',  #8\n",
        "              'B-iiv',  #9\n",
        "              'I-iiv',  #10\n",
        "              'B-pat',  #11\n",
        "              'I-pat',  #12\n",
        "             ]\n",
        "id2label = {i: label for i, label in enumerate(label_list)}\n",
        "label2id = {label: i for i, label in enumerate(label_list)}"
      ],
      "metadata": {
        "id": "ssH9eTJQyoOz"
      },
      "id": "ssH9eTJQyoOz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Expand results so no longer lists of lists\n",
        "for_cm_true = [y for x in all_true for y in x]\n",
        "print(len(for_cm_true))\n",
        "for_cm_pred = [y for x in all_pred for y in x]\n",
        "print(len(for_cm_pred))"
      ],
      "metadata": {
        "id": "FLhtl1tAy3nD"
      },
      "id": "FLhtl1tAy3nD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_name = list(label2id.keys())\n",
        "print(labels_name)\n",
        "labels_id = list(id2label.keys())\n",
        "print(labels_id)"
      ],
      "metadata": {
        "id": "7uTX_ILQy3ke"
      },
      "id": "7uTX_ILQy3ke",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import sklearn.metrics as skm\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "HZEKpaoTy3iI"
      },
      "id": "HZEKpaoTy3iI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_id_11 = list(id2label.keys())[1:]\n",
        "print(labels_id_11)\n",
        "labels_name_11 = list(label2id.keys())[1:]\n",
        "print(labels_name_11)"
      ],
      "metadata": {
        "id": "quKjireWy3fy"
      },
      "id": "quKjireWy3fy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(for_cm_true, for_cm_pred, labels =labels_id_11)"
      ],
      "metadata": {
        "id": "1qVh4_JSy3bO"
      },
      "id": "1qVh4_JSy3bO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize\n",
        "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "fig, ax = plt.subplots(figsize=(8,8))\n",
        "sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=labels_name_11, yticklabels=labels_name_11)\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "#plt.savefig('plot4.jpg', format='jpg', dpi=1200)\n",
        "plt.show(block=False)"
      ],
      "metadata": {
        "id": "udNqUVzBy3Yu"
      },
      "id": "udNqUVzBy3Yu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "confusion_np = cmn#.np()\n",
        "FP = confusion_np.sum(axis=0) - np.diag(confusion_np)\n",
        "FN = confusion_np.sum(axis=1) - np.diag(confusion_np)\n",
        "TP = np.diag(confusion_np)\n",
        "TN = confusion_np.sum() - (FP + FN + TP)\n",
        "\n",
        "# Sensitivity, hit rate, recall, or true positive rate\n",
        "TPR = TP/(TP+FN)\n",
        "# Specificity or true negative rate\n",
        "TNR = TN/(TN+FP)\n",
        "# Precision or positive predictive value\n",
        "PPV = TP/(TP+FP)\n",
        "# Negative predictive value\n",
        "NPV = TN/(TN+FN)\n",
        "# Fall out or false positive rate\n",
        "FPR = FP/(FP+TN)\n",
        "# False negative rate\n",
        "FNR = FN/(TP+FN)\n",
        "# False discovery rate\n",
        "FDR = FP/(TP+FP)\n",
        "#F1-Score\n",
        "F1 = TP/(TP+.5*(FP+FN))\n",
        "\n",
        "# Overall accuracy\n",
        "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
        "\n",
        "metrics = {'FP':FP, 'FN':FN, 'TP':TP, 'TN':TN, 'TPR':TPR, 'TNR':TNR, 'PPV':PPV, 'NPV':NPV, 'FPR':FPR, 'FNR':FNR, 'FDR':FDR, 'F1':F1, 'ACC':ACC}\n",
        "for k, v in metrics.items():\n",
        "    print(k)\n",
        "    for x in zip(labels_name_11, list(v)):\n",
        "        print(x[0], x[1])\n",
        "    print()"
      ],
      "metadata": {
        "id": "tWljByxUy3WE"
      },
      "id": "tWljByxUy3WE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_tns = [\n",
        " 'rce', #1\n",
        " 'oob', #2\n",
        " 'xss', #3\n",
        " 'sql', #4\n",
        " 'iiv', #5\n",
        " 'pat'  #6\n",
        " ]\n",
        "\n",
        "test_tns_ids = [ 1, 2, 3, 4, 5, 6]\n",
        "\n",
        "cwes = [\n",
        " 'CWE-94', #1\n",
        " 'CWE-787', #2\n",
        " 'CWE-79', #3\n",
        " 'CWE-89', #4\n",
        " 'CWE-20', #5\n",
        " 'CWE-22'  #6\n",
        " ]\n",
        "\n",
        "\n",
        "id2label_test = {i: label for i, label in enumerate(test_tns,1)}\n",
        "label2id_test = {label: i for i, label in enumerate(test_tns,1)}\n",
        "\n",
        "all_true_test = [label2id_test[id2label[x].split('-')[1]] if x!=0 else 0 for x in for_cm_true]\n",
        "all_pred_test = [label2id_test[id2label[x].split('-')[1]] if x!=0 else 0 for x in for_cm_pred]\n",
        "\n",
        "#print(classification_report(all_true_test, all_pred_test, target_names=test_tns))"
      ],
      "metadata": {
        "id": "MuXMNjeezBRD"
      },
      "id": "MuXMNjeezBRD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm7 = confusion_matrix(all_true_test, all_pred_test, labels=test_tns_ids)\n",
        "cmn7 = cm7.astype('float') / cm7.sum(axis=1)[:, np.newaxis]"
      ],
      "metadata": {
        "id": "vpoIw05jzBO9"
      },
      "id": "vpoIw05jzBO9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion7_np = cmn7\n",
        "FP = confusion7_np.sum(axis=0) - np.diag(confusion7_np)\n",
        "FN = confusion7_np.sum(axis=1) - np.diag(confusion7_np)\n",
        "TP = np.diag(confusion7_np)\n",
        "TN = confusion7_np.sum() - (FP + FN + TP)\n",
        "\n",
        "\n",
        "# Sensitivity, hit rate, recall, or true positive rate\n",
        "TPR = TP/(TP+FN)\n",
        "# Specificity or true negative rate\n",
        "TNR = TN/(TN+FP)\n",
        "# Precision or positive predictive value\n",
        "PPV = TP/(TP+FP)\n",
        "# Negative predictive value\n",
        "NPV = TN/(TN+FN)\n",
        "# Fall out or false positive rate\n",
        "FPR = FP/(FP+TN)\n",
        "# False negative rate\n",
        "FNR = FN/(TP+FN)\n",
        "# False discovery rate\n",
        "FDR = FP/(TP+FP)\n",
        "#F1-Score\n",
        "F1 = TP/(TP+.5*(FP+FN))\n",
        "\n",
        "# Overall accuracy\n",
        "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
        "\n",
        "metrics = {'FP':FP, 'FN':FN, 'TP':TP, 'TN':TN, 'TPR':TPR, 'TNR':TNR, 'PPV':PPV, 'NPV':NPV, 'FPR':FPR, 'FNR':FNR, 'FDR':FDR, 'F1':F1, 'ACC':ACC}\n",
        "for k, v in metrics.items():\n",
        "    print(k)\n",
        "    for x in zip(test_tns, list(v)):\n",
        "        print(x[0], x[1])\n",
        "    print()"
      ],
      "metadata": {
        "id": "qoapjGRtzBMY"
      },
      "id": "qoapjGRtzBMY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(8,8))\n",
        "sns.heatmap(cmn7, annot=True, fmt='.2f', xticklabels=cwes, yticklabels=cwes)\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show(block=False)"
      ],
      "metadata": {
        "id": "0EB-tZgczBJu"
      },
      "id": "0EB-tZgczBJu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns1 = sns.heatmap(cmn7, annot=True, fmt='.2f', ax=ax1, xticklabels=cwes, yticklabels=cwes, annot_kws={\"size\": 15})\n",
        "plt.ylabel('Actual', fontsize=15)\n",
        "plt.xlabel('Predicted', fontsize=15)\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "cbar1 = sns1.collections[0].colorbar\n",
        "cbar1.ax.tick_params(labelsize=14)\n",
        "\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns2 = sns.heatmap(cmn, annot=True, fmt='.2f', ax=ax2, xticklabels=labels_name_11, yticklabels=labels_name_11, annot_kws={\"size\": 14})\n",
        "plt.ylabel('Actual', fontsize=15)\n",
        "plt.xlabel('Predicted', fontsize=15)\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "cbar2 = sns2.collections[0].colorbar\n",
        "cbar2.ax.tick_params(labelsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('Figure_A1.jpg', format='jpg', dpi=1200)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5xlNaPAjzBHJ"
      },
      "id": "5xlNaPAjzBHJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BoTME1-Xy3Tf"
      },
      "id": "BoTME1-Xy3Tf",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}